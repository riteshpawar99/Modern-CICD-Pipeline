# üöÄ Modern CI/CD Pipeline ‚Äî Visual Reference & Deep Dive

> An interactive, end-to-end visual reference for understanding how modern software delivery pipelines work ‚Äî from a single `git push` all the way to a live, observable production deployment.

![CI/CD Pipeline](https://img.shields.io/badge/CI%2FCD-Pipeline-blue?style=for-the-badge&logo=githubactions&logoColor=white)
![Status](https://img.shields.io/badge/Status-Complete-brightgreen?style=for-the-badge)
![Stack](https://img.shields.io/badge/Stack-Docker%20%7C%20K8s%20%7C%20ArgoCD-orange?style=for-the-badge)
![License](https://img.shields.io/badge/License-MIT-lightgrey?style=for-the-badge)

---

## üìå What This Project Is

This is a hand-built, fully interactive visual reference that maps out every stage of a modern CI/CD (Continuous Integration / Continuous Delivery) pipeline ‚Äî the exact same architecture pattern used by high-performing engineering teams at companies like Netflix, Shopify, Stripe, and thousands of others.

The goal was not just to list tools, but to genuinely understand *why* each stage exists, what problem it solves, and how the stages connect into a coherent system. Every section you see was researched, designed, and implemented from scratch using vanilla HTML, CSS, and JavaScript ‚Äî no frameworks, no templates.

---

## üß† Why I Built This & What It Demonstrates

I built this to solidify my understanding of modern DevOps practices. Reading about CI/CD is one thing; forcing yourself to explain every stage clearly enough to *visualize and teach it* is another level entirely. By the time I had designed the pipeline flow, the environment progression, the DORA metrics, and the toolchain section, I had a mental model of the entire software delivery lifecycle that I couldn't get from a tutorial alone.

This project demonstrates that I understand:

- How pipelines are structured as sequential, gate-based stages where a failure stops progress immediately
- Why every commit ‚Äî not just releases ‚Äî should trigger the full pipeline
- The difference between Continuous Integration, Continuous Delivery, and Continuous Deployment, and why they're distinct concepts even though they're always grouped together
- What GitOps means at a conceptual level and how it differs from traditional "push-based" deployments
- Why observability is not an afterthought but a core stage of delivery, closing the feedback loop back into development

---

## üó∫Ô∏è The Pipeline Architecture

The pipeline is organized as **7 sequential stages**. The key insight I want to communicate here is that these stages are not arbitrary ‚Äî each one represents a specific kind of confidence you are building about your code before it reaches users. The further right a stage sits, the more expensive it becomes to fix a failure there. This is why the cheapest, fastest checks (lint, type checks) run first.

### Stage 1 ‚Äî Source Control

Everything begins with a `git push`. This is the heartbeat trigger of the entire system. I designed this stage to emphasize the importance of branch strategy (trunk-based development or GitFlow) and the role of Pull Requests ‚Äî not just as a code review mechanism, but as a formal gate that prevents unreviewed code from entering the pipeline at all.

Branch protection rules on `main` enforce that no developer, regardless of seniority, can bypass the pipeline by pushing directly. This is a cultural as much as a technical decision.

### Stage 2 ‚Äî Build

The build stage installs dependencies (critically using a lockfile ‚Äî `npm ci` rather than `npm install` ‚Äî for reproducibility), runs static analysis tools like ESLint and the TypeScript compiler, and produces a **Docker image**. The image is the atomic unit of deployment. Every subsequent stage in the pipeline works with this image, not raw source code.

A key design choice I understood here is **multi-stage Docker builds**: the builder stage has all your dev tools and compilers, but the final image is stripped down to only what's needed to run the app. This dramatically reduces attack surface and image size.

### Stage 3 ‚Äî Test

Testing is the most nuanced stage. I structured it around three distinct layers, because understanding *why* each layer exists is what separates engineers who write tests from engineers who understand testing strategy:

The **unit test** layer runs fast and in complete isolation. Every external dependency (database, API) is mocked. These tests prove your individual functions and modules behave correctly in isolation.

The **integration test** layer uses real infrastructure ‚Äî an actual Postgres container, a real Redis instance ‚Äî spun up ephemerally via Testcontainers or Docker Compose service definitions. These tests prove that your code and your dependencies work correctly *together*.

The **End-to-End (E2E) test** layer, using Playwright or Cypress, simulates a real human user clicking through the application. These are the slowest and most brittle tests but provide the highest confidence because they test the entire system from the user's perspective.

A coverage threshold gate (typically 80%) prevents engineers from shipping code that is technically working but entirely untested.

### Stage 4 ‚Äî Security Scanning

This stage is where I think a lot of beginner CI/CD pipelines fall short. Security is not just a final checkbox ‚Äî it is an integrated part of every delivery cycle. I designed this stage to cover four distinct threat surfaces:

**SAST (Static Application Security Testing)** analyzes your source code for known vulnerability patterns without running the code ‚Äî things like SQL injection, path traversal, and insecure deserialization. GitHub's CodeQL is a powerful free option here.

**Dependency scanning** (Snyk, Dependabot, Trivy) checks every third-party package your application depends on against databases of known CVEs. The Log4Shell vulnerability in 2021 is the canonical example of why this matters ‚Äî millions of applications were vulnerable because of a single transitive dependency nobody was watching.

**Container image scanning** extends dependency scanning to the operating system layer of your Docker image, catching vulnerable OS packages in your base image.

**Secret detection** (gitleaks, truffleHog) scans the entire git history for accidentally committed API keys, passwords, or tokens. The "history" part is critical ‚Äî removing a secret from the latest commit does not remove it from git history, and secret detection tools know this.

### Stage 5 ‚Äî Artifact Registry

Once code is proven clean and tested, the Docker image is tagged and pushed to a private container registry (Amazon ECR, Google Artifact Registry, GitHub Container Registry). The tagging strategy I documented is important: always tag with the **git commit SHA** for traceability, plus a semantic version for human readability. Never deploy an image tagged only as `latest` to production ‚Äî `latest` is mutable and non-deterministic.

I also included **image signing with cosign** (part of the Sigstore project), which is increasingly a production requirement. Signing creates a cryptographic attestation that the image was produced by your trusted CI system and has not been tampered with since.

### Stage 6 ‚Äî Deploy (GitOps)

Deployment is where I had the deepest learning. The modern approach is **GitOps**, and understanding it properly changes how you think about deployments entirely.

In a traditional "push-based" model, your CI pipeline runs `kubectl apply` or `helm upgrade` directly against the cluster. This works, but it creates problems: what is the cluster's desired state? Who deployed what and when? How do you roll back?

In a GitOps model, a separate **config repository** contains your Kubernetes manifests (typically packaged as Helm charts). A tool like **ArgoCD** or **Flux** runs *inside* the cluster and continuously compares the cluster's actual state to what the config repo says it should be. When your CI pipeline updates the image tag in the config repo and pushes, ArgoCD detects the difference and reconciles the cluster automatically.

The result is that your git history *is* your deployment history. Rollback is `git revert`. Auditing is `git log`. Disaster recovery is re-pointing ArgoCD at your repo.

For production deployments, I designed in a **canary strategy** via Argo Rollouts: 10% of traffic goes to the new version, the system watches error rates and latency for 5‚Äì10 minutes, then gradually shifts more traffic. An analysis template can trigger automatic rollback if error thresholds are breached ‚Äî no human needs to be awake to catch a bad deploy at 3am.

### Stage 7 ‚Äî Observe

The pipeline does not end at deployment ‚Äî that's the mistake that leads to silent failures. Observability closes the loop. I built this stage around the three pillars of observability:

**Logs** tell you what happened (events with timestamps and context). **Metrics** tell you how the system is performing (request rate, error rate, latency ‚Äî the "golden signals"). **Traces** (via OpenTelemetry) tell you *where* time is being spent across a distributed system, connecting a single user request across multiple microservices.

OpenTelemetry is the key technology I highlighted here because it solves the vendor lock-in problem: instrument your application once using the OTel SDK, and export to any backend ‚Äî Datadog, Jaeger, Honeycomb, Grafana Tempo ‚Äî by changing a config file, not your application code.

---

## üåç Deployment Environment Progression

The visual also maps out the six-environment journey that code travels through:

**Local Dev** ‚Üí **PR/Branch** (isolated, per-PR) ‚Üí **CI Runner** (ephemeral, automated) ‚Üí **Dev/QA** (persistent, team-shared) ‚Üí **Staging** (production mirror) ‚Üí **Production**

The critical insight here is **Staging must be a production mirror**. It needs the same infrastructure size, the same network configuration, the same data shape. If Staging is a cut-down version of production, it provides false confidence, and you will regularly encounter "works in staging, broken in prod" failures that erode trust in your whole delivery system.

---

## üìä DORA Metrics ‚Äî How I Measure Pipeline Health

I included the four DORA (DevOps Research and Assessment) metrics because they are the industry-standard way to measure whether your pipeline is actually working or just running. They matter because they are *outcome* metrics, not activity metrics ‚Äî they tell you if all your tooling is actually making delivery faster and safer.

| Metric | What it measures | Elite benchmark |
|---|---|---|
| **Lead Time for Changes** | Time from commit to production | < 1 hour |
| **Deployment Frequency** | How often you deploy to prod | Multiple times/day |
| **Mean Time to Restore** | How fast you recover from incidents | < 5 minutes |
| **Change Failure Rate** | % of deploys that cause an incident | < 5% |

A slow, fragile pipeline shows up immediately in these numbers. If your lead time is two weeks, your pipeline has a bottleneck ‚Äî and these metrics will tell you it's there, even if you can't see it yet.

---

## üõ†Ô∏è Full Toolchain Reference

| Stage | Primary Tools | Purpose |
|---|---|---|
| Source | Git, GitHub, Conventional Commits | Version control, trigger mechanism, commit hygiene |
| Build | GitHub Actions, Docker BuildKit, ESLint, tsc | Compilation, static analysis, image creation |
| Test | Jest, Playwright, Testcontainers, Codecov | Unit, E2E, integration testing, coverage reporting |
| Security | CodeQL, Trivy, Snyk, gitleaks | SAST, container CVE scanning, secret detection |
| Artifact | Amazon ECR, cosign, Syft | Image storage, signing, SBOM generation |
| Deploy | Kubernetes, ArgoCD, Argo Rollouts, Helm | GitOps reconciliation, canary deployments |
| Observe | OpenTelemetry, Datadog, PagerDuty | Logs, metrics, traces, alerting, on-call |

---

## üí° Key Concepts I Internalized Building This

**Shift left on security** ‚Äî the earlier in the pipeline you catch a problem, the cheaper it is to fix. A linting error caught at build time costs seconds. A security vulnerability found after production deployment costs days and potentially customers.

**Pipelines are a trust-building machine** ‚Äî each stage is not just "running a tool," it is answering a specific question. "Does this code compile?" "Does it behave correctly?" "Is it free of known vulnerabilities?" "Has it been approved by a human?" The chain of yes-answers is what earns the right to reach production.

**Everything as code** ‚Äî the pipeline itself (YAML), the infrastructure (Terraform/Bicep), the Kubernetes manifests (Helm charts), the alert rules (Prometheus YAML) ‚Äî none of these should live in a UI or someone's head. They should be in git, reviewed, versioned, and tested just like application code.

**Reproducibility over convenience** ‚Äî `npm ci` instead of `npm install`, pinned base images in Dockerfiles, lockfiles committed to git, deterministic builds. Every shortcut in reproducibility is a future debugging session you can't explain.

---

## üöÄ How to Run / View

Simply open `index.html` in any modern browser. No build step, no server, no dependencies ‚Äî the entire interactive diagram is self-contained.

```bash
# Clone the repo
git clone https://github.com/yourusername/cicd-pipeline-visual.git

# Open directly in browser
open index.html   # macOS
xdg-open index.html  # Linux
start index.html  # Windows
```

---

## üìÅ Project Structure

```
cicd-pipeline-visual/
‚îú‚îÄ‚îÄ index.html          # Complete interactive pipeline diagram
‚îú‚îÄ‚îÄ README.md           # This file
‚îî‚îÄ‚îÄ assets/             # (optional) screenshots for README
    ‚îî‚îÄ‚îÄ preview.png
```

---

## üîÆ What I'd Build Next

If I were to extend this into a real working implementation rather than a visual reference, the natural next step would be to:

1. Build a real GitHub Actions workflow file that implements every stage documented here
2. Set up a real ArgoCD instance on a local Kubernetes cluster (k3d or kind) to experience GitOps hands-on
3. Instrument a sample application with OpenTelemetry and route traces to Jaeger to understand distributed tracing in practice

Understanding the architecture is step one. The next step is getting your hands dirty implementing it.

---

## üìö References & Further Reading

- [DORA State of DevOps Report](https://dora.dev/research/) ‚Äî the definitive research behind the four key metrics
- [OpenGitOps Principles](https://opengitops.dev/) ‚Äî the formal definition of GitOps
- [Sigstore / cosign Documentation](https://docs.sigstore.dev/) ‚Äî software supply chain security
- [OWASP DevSecOps Guideline](https://owasp.org/www-project-devsecops-guideline/) ‚Äî integrating security into every pipeline stage
- [OpenTelemetry Documentation](https://opentelemetry.io/docs/) ‚Äî the vendor-neutral observability standard

---

## üë§ Author

Built with a focus on understanding *why*, not just *what*. If you're learning CI/CD and want to discuss any of the concepts here, feel free to open an issue or reach out.

-RITESSH PAWAR
riteshpawar754@gmail.com
---

*"The goal of CI/CD is not to automate deployments. It is to make the cost of deploying so low that you can do it continuously ‚Äî and in doing so, make every individual change smaller, safer, and easier to reason about."*
